/* Querying */
Enter output directory name: EffNetB0_50ep-BS64_LR1e-3-LS5e-2-BA-AMP
/* Initializing */
Using device: cuda:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU)
/* Training */
Epoch 1, Batch 0, Loss: 1.9835
Epoch 1, Batch 40, Loss: 0.9557
Epoch 1, Batch 80, Loss: 0.5456
Epoch 1, Batch 120, Loss: 0.6993
Epoch 1/50, Loss: 0.8698, Time: 16.96s
Epoch 2, Batch 0, Loss: 0.6270
Epoch 2, Batch 40, Loss: 0.4080
Epoch 2, Batch 80, Loss: 0.4791
Epoch 2, Batch 120, Loss: 0.5444
Epoch 2/50, Loss: 0.4778, Time: 12.79s
Epoch 3, Batch 0, Loss: 0.4846
Epoch 3, Batch 40, Loss: 0.5788
Epoch 3, Batch 80, Loss: 0.3319
Epoch 3, Batch 120, Loss: 0.2914
Epoch 3/50, Loss: 0.3737, Time: 12.61s
Epoch 4, Batch 0, Loss: 0.3101
Epoch 4, Batch 40, Loss: 0.3187
Epoch 4, Batch 80, Loss: 0.3477
Epoch 4, Batch 120, Loss: 0.2837
Epoch 4/50, Loss: 0.3504, Time: 12.88s
Epoch 5, Batch 0, Loss: 0.6346
Epoch 5, Batch 40, Loss: 0.2969
Epoch 5, Batch 80, Loss: 0.3036
Epoch 5, Batch 120, Loss: 0.2921
Epoch 5/50, Loss: 0.3449, Time: 13.04s
Epoch 6, Batch 0, Loss: 0.2824
Epoch 6, Batch 40, Loss: 0.3105
Epoch 6, Batch 80, Loss: 0.2804
Epoch 6, Batch 120, Loss: 0.2706
Epoch 6/50, Loss: 0.3374, Time: 13.16s
Epoch 7, Batch 0, Loss: 0.2932
Epoch 7, Batch 40, Loss: 0.2883
Epoch 7, Batch 80, Loss: 0.4751
Epoch 7, Batch 120, Loss: 0.2736
Epoch 7/50, Loss: 0.3083, Time: 12.45s
Epoch 8, Batch 0, Loss: 0.2775
Epoch 8, Batch 40, Loss: 0.2721
Epoch 8, Batch 80, Loss: 0.2730
Epoch 8, Batch 120, Loss: 0.2956
Epoch 8/50, Loss: 0.2957, Time: 13.06s
Epoch 9, Batch 0, Loss: 0.2830
Epoch 9, Batch 40, Loss: 0.3174
Epoch 9, Batch 80, Loss: 0.2990
Epoch 9, Batch 120, Loss: 0.2799
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 9/50, Loss: 0.3125, Time: 12.73s
Epoch 10, Batch 0, Loss: 0.2796
Epoch 10, Batch 40, Loss: 0.3698
Epoch 10, Batch 80, Loss: 0.4608
Epoch 10, Batch 120, Loss: 0.2730
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 10/50, Loss: 0.3043, Time: 12.49s
Epoch 11, Batch 0, Loss: 0.2898
Epoch 11, Batch 40, Loss: 0.2841
Epoch 11, Batch 80, Loss: 0.2645
Epoch 11, Batch 120, Loss: 0.2661
Epoch 11/50, Loss: 0.2943, Time: 12.55s
Epoch 12, Batch 0, Loss: 0.2821
Epoch 12, Batch 40, Loss: 0.2828
Epoch 12, Batch 80, Loss: 0.2715
Epoch 12, Batch 120, Loss: 0.2751
Epoch 12/50, Loss: 0.2924, Time: 12.53s
Epoch 13, Batch 0, Loss: 0.3156
Epoch 13, Batch 40, Loss: 0.2756
Epoch 13, Batch 80, Loss: 0.2723
Epoch 13, Batch 120, Loss: 0.2893
Epoch 13/50, Loss: 0.2850, Time: 12.51s
Epoch 14, Batch 0, Loss: 0.2666
Epoch 14, Batch 40, Loss: 0.2714
Epoch 14, Batch 80, Loss: 0.2623
Epoch 14, Batch 120, Loss: 0.3011
Epoch 14/50, Loss: 0.2846, Time: 12.88s
Epoch 15, Batch 0, Loss: 0.2678
Epoch 15, Batch 40, Loss: 0.3160
Epoch 15, Batch 80, Loss: 0.3076
Epoch 15, Batch 120, Loss: 0.2683
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 15/50, Loss: 0.3003, Time: 12.83s
Epoch 16, Batch 0, Loss: 0.2705
Epoch 16, Batch 40, Loss: 0.2621
Epoch 16, Batch 80, Loss: 0.2644
Epoch 16, Batch 120, Loss: 0.3029
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 16/50, Loss: 0.2986, Time: 12.87s
Epoch 17, Batch 0, Loss: 0.2689
Epoch 17, Batch 40, Loss: 0.3267
Epoch 17, Batch 80, Loss: 0.2840
Epoch 17, Batch 120, Loss: 0.2973
NOTICE: Validation loss increased in this epoch (3/51).
Epoch 17/50, Loss: 0.2910, Time: 12.82s
Epoch 18, Batch 0, Loss: 0.2857
Epoch 18, Batch 40, Loss: 0.2675
Epoch 18, Batch 80, Loss: 0.2767
Epoch 18, Batch 120, Loss: 0.2654
Epoch 18/50, Loss: 0.2769, Time: 12.66s
Epoch 19, Batch 0, Loss: 0.2657
Epoch 19, Batch 40, Loss: 0.2621
Epoch 19, Batch 80, Loss: 0.2651
Epoch 19, Batch 120, Loss: 0.2618
Epoch 19/50, Loss: 0.2711, Time: 12.65s
Epoch 20, Batch 0, Loss: 0.2643
Epoch 20, Batch 40, Loss: 0.2601
Epoch 20, Batch 80, Loss: 0.2600
Epoch 20, Batch 120, Loss: 0.2642
Epoch 20/50, Loss: 0.2709, Time: 12.57s
Epoch 21, Batch 0, Loss: 0.2616
Epoch 21, Batch 40, Loss: 0.2862
Epoch 21, Batch 80, Loss: 0.2622
Epoch 21, Batch 120, Loss: 0.2652
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 21/50, Loss: 0.2728, Time: 12.47s
Epoch 22, Batch 0, Loss: 0.2589
Epoch 22, Batch 40, Loss: 0.2628
Epoch 22, Batch 80, Loss: 0.2643
Epoch 22, Batch 120, Loss: 0.2920
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 22/50, Loss: 0.2737, Time: 12.60s
Epoch 23, Batch 0, Loss: 0.2643
Epoch 23, Batch 40, Loss: 0.2613
Epoch 23, Batch 80, Loss: 0.2826
Epoch 23, Batch 120, Loss: 0.2613
NOTICE: Validation loss increased in this epoch (3/51).
Epoch 23/50, Loss: 0.2724, Time: 13.08s
Epoch 24, Batch 0, Loss: 0.2639
Epoch 24, Batch 40, Loss: 0.2623
Epoch 24, Batch 80, Loss: 0.2649
Epoch 24, Batch 120, Loss: 0.2639
Epoch 24/50, Loss: 0.2688, Time: 13.04s
Epoch 25, Batch 0, Loss: 0.2708
Epoch 25, Batch 40, Loss: 0.2652
Epoch 25, Batch 80, Loss: 0.2593
Epoch 25, Batch 120, Loss: 0.2633
Epoch 25/50, Loss: 0.2677, Time: 12.81s
Epoch 26, Batch 0, Loss: 0.2627
Epoch 26, Batch 40, Loss: 0.2619
Epoch 26, Batch 80, Loss: 0.2584
Epoch 26, Batch 120, Loss: 0.2594
Epoch 26/50, Loss: 0.2676, Time: 12.65s
Epoch 27, Batch 0, Loss: 0.2620
Epoch 27, Batch 40, Loss: 0.2619
Epoch 27, Batch 80, Loss: 0.2607
Epoch 27, Batch 120, Loss: 0.2630
Epoch 27/50, Loss: 0.2650, Time: 12.85s
Epoch 28, Batch 0, Loss: 0.2577
Epoch 28, Batch 40, Loss: 0.2601
Epoch 28, Batch 80, Loss: 0.2647
Epoch 28, Batch 120, Loss: 0.2610
Epoch 28/50, Loss: 0.2649, Time: 12.74s
Epoch 29, Batch 0, Loss: 0.2740
Epoch 29, Batch 40, Loss: 0.2583
Epoch 29, Batch 80, Loss: 0.2582
Epoch 29, Batch 120, Loss: 0.2641
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 29/50, Loss: 0.2748, Time: 12.80s
Epoch 30, Batch 0, Loss: 0.2587
Epoch 30, Batch 40, Loss: 0.2607
Epoch 30, Batch 80, Loss: 0.2600
Epoch 30, Batch 120, Loss: 0.2593
Epoch 30/50, Loss: 0.2624, Time: 13.06s
Epoch 31, Batch 0, Loss: 0.2605
Epoch 31, Batch 40, Loss: 0.2596
Epoch 31, Batch 80, Loss: 0.2586
Epoch 31, Batch 120, Loss: 0.2627
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 31/50, Loss: 0.2626, Time: 12.82s
Epoch 32, Batch 0, Loss: 0.2576
Epoch 32, Batch 40, Loss: 0.2599
Epoch 32, Batch 80, Loss: 0.2701
Epoch 32, Batch 120, Loss: 0.2604
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 32/50, Loss: 0.2627, Time: 12.69s
Epoch 33, Batch 0, Loss: 0.2612
Epoch 33, Batch 40, Loss: 0.2630
Epoch 33, Batch 80, Loss: 0.2582
Epoch 33, Batch 120, Loss: 0.2614
Epoch 33/50, Loss: 0.2623, Time: 12.81s
Epoch 34, Batch 0, Loss: 0.2595
Epoch 34, Batch 40, Loss: 0.2595
Epoch 34, Batch 80, Loss: 0.2640
Epoch 34, Batch 120, Loss: 0.2587
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 34/50, Loss: 0.2726, Time: 12.67s
Epoch 35, Batch 0, Loss: 0.2587
Epoch 35, Batch 40, Loss: 0.2672
Epoch 35, Batch 80, Loss: 0.2636
Epoch 35, Batch 120, Loss: 0.2801
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 35/50, Loss: 0.2677, Time: 12.56s
Epoch 36, Batch 0, Loss: 0.2623
Epoch 36, Batch 40, Loss: 0.2614
Epoch 36, Batch 80, Loss: 0.2712
Epoch 36, Batch 120, Loss: 0.2589
NOTICE: Validation loss increased in this epoch (3/51).
Epoch 36/50, Loss: 0.2652, Time: 12.80s
Epoch 37, Batch 0, Loss: 0.2586
Epoch 37, Batch 40, Loss: 0.2643
Epoch 37, Batch 80, Loss: 0.2600
Epoch 37, Batch 120, Loss: 0.2595
NOTICE: Validation loss increased in this epoch (4/51).
Epoch 37/50, Loss: 0.2631, Time: 13.14s
Epoch 38, Batch 0, Loss: 0.2608
Epoch 38, Batch 40, Loss: 0.2593
Epoch 38, Batch 80, Loss: 0.2639
Epoch 38, Batch 120, Loss: 0.2598
NOTICE: Validation loss increased in this epoch (5/51).
Epoch 38/50, Loss: 0.2626, Time: 12.55s
Epoch 39, Batch 0, Loss: 0.2572
Epoch 39, Batch 40, Loss: 0.2593
Epoch 39, Batch 80, Loss: 0.2665
Epoch 39, Batch 120, Loss: 0.2738
NOTICE: Validation loss increased in this epoch (6/51).
Epoch 39/50, Loss: 0.2628, Time: 12.52s
Epoch 40, Batch 0, Loss: 0.2587
Epoch 40, Batch 40, Loss: 0.2605
Epoch 40, Batch 80, Loss: 0.2609
Epoch 40, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (7/51).
Epoch 40/50, Loss: 0.2692, Time: 12.64s
Epoch 41, Batch 0, Loss: 0.2599
Epoch 41, Batch 40, Loss: 0.2588
Epoch 41, Batch 80, Loss: 0.2578
Epoch 41, Batch 120, Loss: 0.2570
NOTICE: Validation loss increased in this epoch (8/51).
Epoch 41/50, Loss: 0.2627, Time: 12.76s
Epoch 42, Batch 0, Loss: 0.2624
Epoch 42, Batch 40, Loss: 0.2607
Epoch 42, Batch 80, Loss: 0.2587
Epoch 42, Batch 120, Loss: 0.2592
NOTICE: Validation loss increased in this epoch (9/51).
Epoch 42/50, Loss: 0.2726, Time: 12.82s
Epoch 43, Batch 0, Loss: 0.2595
Epoch 43, Batch 40, Loss: 0.2575
Epoch 43, Batch 80, Loss: 0.2608
Epoch 43, Batch 120, Loss: 0.2585
NOTICE: Validation loss increased in this epoch (10/51).
Epoch 43/50, Loss: 0.2631, Time: 12.59s
Epoch 44, Batch 0, Loss: 0.2580
Epoch 44, Batch 40, Loss: 0.2599
Epoch 44, Batch 80, Loss: 0.2619
Epoch 44, Batch 120, Loss: 0.2606
NOTICE: Validation loss increased in this epoch (11/51).
Epoch 44/50, Loss: 0.2715, Time: 12.89s
Epoch 45, Batch 0, Loss: 0.2588
Epoch 45, Batch 40, Loss: 0.2571
Epoch 45, Batch 80, Loss: 0.2576
Epoch 45, Batch 120, Loss: 0.2642
NOTICE: Validation loss increased in this epoch (12/51).
Epoch 45/50, Loss: 0.2718, Time: 12.61s
Epoch 46, Batch 0, Loss: 0.2635
Epoch 46, Batch 40, Loss: 0.2609
Epoch 46, Batch 80, Loss: 0.2573
Epoch 46, Batch 120, Loss: 0.2601
Epoch 46/50, Loss: 0.2616, Time: 12.73s
Epoch 47, Batch 0, Loss: 0.2586
Epoch 47, Batch 40, Loss: 0.2570
Epoch 47, Batch 80, Loss: 0.2576
Epoch 47, Batch 120, Loss: 0.2585
Epoch 47/50, Loss: 0.2605, Time: 13.00s
Epoch 48, Batch 0, Loss: 0.2604
Epoch 48, Batch 40, Loss: 0.2571
Epoch 48, Batch 80, Loss: 0.2581
Epoch 48, Batch 120, Loss: 0.2576
NOTICE: Validation loss increased in this epoch (1/51).
Epoch 48/50, Loss: 0.2612, Time: 13.03s
Epoch 49, Batch 0, Loss: 0.2590
Epoch 49, Batch 40, Loss: 0.2587
Epoch 49, Batch 80, Loss: 0.2699
Epoch 49, Batch 120, Loss: 0.2613
NOTICE: Validation loss increased in this epoch (2/51).
Epoch 49/50, Loss: 0.2721, Time: 13.15s
Epoch 50, Batch 0, Loss: 0.2579
Epoch 50, Batch 40, Loss: 0.2567
Epoch 50, Batch 80, Loss: 0.2758
Epoch 50, Batch 120, Loss: 0.2613
NOTICE: Validation loss increased in this epoch (3/51).
Epoch 50/50, Loss: 0.2607, Time: 12.36s
Total time spent in training: 642.28s
/* Validation */
Validation Loss: 0.2826, Accuracy: 99.05%
/* Saving */
Model saved to output/EffNetB0_50ep-BS64_LR1e-3-LS5e-2-BA-AMP\model-EffNetB0_50ep-BS64_LR1e-3-LS5e-2-BA-AMP.pth
Confusion matrix saved to output/EffNetB0_50ep-BS64_LR1e-3-LS5e-2-BA-AMP\cm-EffNetB0_50ep-BS64_LR1e-3-LS5e-2-BA-AMP.png
