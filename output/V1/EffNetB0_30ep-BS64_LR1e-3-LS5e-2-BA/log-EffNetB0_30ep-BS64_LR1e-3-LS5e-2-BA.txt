/* Querying */
Enter output directory name: EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA
'EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA' already exists. Overwrite? (Y/N): Y
Overwriting existing output...
/* Initializing */
Using device: cuda:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU)
/* Training */
Epoch 1, Batch 0, Loss: 1.9695
Epoch 1, Batch 10, Loss: 0.7519
Epoch 1, Batch 20, Loss: 0.6381
Epoch 1, Batch 30, Loss: 0.5950
Epoch 1/30, Loss: 0.7349, Time: 153.20s
Epoch 2, Batch 0, Loss: 0.4141
Epoch 2, Batch 10, Loss: 0.4264
Epoch 2, Batch 20, Loss: 0.3585
Epoch 2, Batch 30, Loss: 0.3621
Epoch 2/30, Loss: 0.4155, Time: 165.04s
Epoch 3, Batch 0, Loss: 0.3433
Epoch 3, Batch 10, Loss: 0.3664
Epoch 3, Batch 20, Loss: 0.2904
Epoch 3, Batch 30, Loss: 0.3322
Epoch 3/30, Loss: 0.3656, Time: 125.70s
Epoch 4, Batch 0, Loss: 0.2906
Epoch 4, Batch 10, Loss: 0.3017
Epoch 4, Batch 20, Loss: 0.3059
Epoch 4, Batch 30, Loss: 0.3775
Epoch 4/30, Loss: 0.3595, Time: 152.53s
Epoch 5, Batch 0, Loss: 0.2868
Epoch 5, Batch 10, Loss: 0.3569
Epoch 5, Batch 20, Loss: 0.3109
Epoch 5, Batch 30, Loss: 0.3120
Epoch 5/30, Loss: 0.3186, Time: 126.66s
Epoch 6, Batch 0, Loss: 0.2932
Epoch 6, Batch 10, Loss: 0.2865
Epoch 6, Batch 20, Loss: 0.3333
Epoch 6, Batch 30, Loss: 0.2818
Epoch 6/30, Loss: 0.3039, Time: 146.67s
Epoch 7, Batch 0, Loss: 0.2833
Epoch 7, Batch 10, Loss: 0.2944
Epoch 7, Batch 20, Loss: 0.2916
Epoch 7, Batch 30, Loss: 0.2890
Epoch 7/30, Loss: 0.2984, Time: 113.94s
Epoch 8, Batch 0, Loss: 0.2757
Epoch 8, Batch 10, Loss: 0.2834
Epoch 8, Batch 20, Loss: 0.2794
Epoch 8, Batch 30, Loss: 0.3009
Epoch 8/30, Loss: 0.2954, Time: 146.84s
Epoch 9, Batch 0, Loss: 0.2736
Epoch 9, Batch 10, Loss: 0.3366
Epoch 9, Batch 20, Loss: 0.2778
Epoch 9, Batch 30, Loss: 0.2689
Epoch 9/30, Loss: 0.2944, Time: 118.44s
Epoch 10, Batch 0, Loss: 0.2682
Epoch 10, Batch 10, Loss: 0.4194
Epoch 10, Batch 20, Loss: 0.3349
Epoch 10, Batch 30, Loss: 0.2739
NOTICE: Validation loss increased in this epoch (1/4).
Epoch 10/30, Loss: 0.2968, Time: 171.64s
Epoch 11, Batch 0, Loss: 0.2679
Epoch 11, Batch 10, Loss: 0.3391
Epoch 11, Batch 20, Loss: 0.3056
Epoch 11, Batch 30, Loss: 0.2742
Epoch 11/30, Loss: 0.2862, Time: 141.72s
Epoch 12, Batch 0, Loss: 0.2696
Epoch 12, Batch 10, Loss: 0.2719
Epoch 12, Batch 20, Loss: 0.2942
Epoch 12, Batch 30, Loss: 0.2682
NOTICE: Validation loss increased in this epoch (1/4).
Epoch 12/30, Loss: 0.2918, Time: 115.38s
Epoch 13, Batch 0, Loss: 0.2677
Epoch 13, Batch 10, Loss: 0.2997
Epoch 13, Batch 20, Loss: 0.3091
Epoch 13, Batch 30, Loss: 0.2724
Epoch 13/30, Loss: 0.2799, Time: 116.16s
Epoch 14, Batch 0, Loss: 0.2711
Epoch 14, Batch 10, Loss: 0.2710
Epoch 14, Batch 20, Loss: 0.2827
Epoch 14, Batch 30, Loss: 0.2649
NOTICE: Validation loss increased in this epoch (1/4).
Epoch 14/30, Loss: 0.2823, Time: 148.85s
Epoch 15, Batch 0, Loss: 0.3295
Epoch 15, Batch 10, Loss: 0.3021
Epoch 15, Batch 20, Loss: 0.2837
Epoch 15, Batch 30, Loss: 0.3246
NOTICE: Validation loss increased in this epoch (2/4).
Epoch 15/30, Loss: 0.2877, Time: 149.57s
Epoch 16, Batch 0, Loss: 0.2863
Epoch 16, Batch 10, Loss: 0.2711
Epoch 16, Batch 20, Loss: 0.2916
Epoch 16, Batch 30, Loss: 0.2776
Epoch 16/30, Loss: 0.2789, Time: 148.84s
Epoch 17, Batch 0, Loss: 0.2664
Epoch 17, Batch 10, Loss: 0.2637
Epoch 17, Batch 20, Loss: 0.3275
Epoch 17, Batch 30, Loss: 0.2651
Epoch 17/30, Loss: 0.2781, Time: 116.60s
Epoch 18, Batch 0, Loss: 0.2960
Epoch 18, Batch 10, Loss: 0.3128
Epoch 18, Batch 20, Loss: 0.2779
Epoch 18, Batch 30, Loss: 0.3098
NOTICE: Validation loss increased in this epoch (1/4).
Epoch 18/30, Loss: 0.3043, Time: 149.06s
Epoch 19, Batch 0, Loss: 0.2717
Epoch 19, Batch 10, Loss: 0.2715
Epoch 19, Batch 20, Loss: 0.2883
Epoch 19, Batch 30, Loss: 0.2695
NOTICE: Validation loss increased in this epoch (2/4).
Epoch 19/30, Loss: 0.2929, Time: 148.83s
Epoch 20, Batch 0, Loss: 0.2699
Epoch 20, Batch 10, Loss: 0.2972
Epoch 20, Batch 20, Loss: 0.2658
Epoch 20, Batch 30, Loss: 0.2667
NOTICE: Validation loss increased in this epoch (3/4).
Epoch 20/30, Loss: 0.2903, Time: 147.58s
Epoch 21, Batch 0, Loss: 0.2835
Epoch 21, Batch 10, Loss: 0.2712
Epoch 21, Batch 20, Loss: 0.2639
Epoch 21, Batch 30, Loss: 0.2830
Epoch 21/30, Loss: 0.2759, Time: 148.22s
Epoch 22, Batch 0, Loss: 0.2605
Epoch 22, Batch 10, Loss: 0.2625
Epoch 22, Batch 20, Loss: 0.2647
Epoch 22, Batch 30, Loss: 0.2632
Epoch 22/30, Loss: 0.2669, Time: 119.19s
Epoch 23, Batch 0, Loss: 0.2628
Epoch 23, Batch 10, Loss: 0.2604
Epoch 23, Batch 20, Loss: 0.2618
Epoch 23, Batch 30, Loss: 0.2694
Epoch 23/30, Loss: 0.2654, Time: 149.25s
Epoch 24, Batch 0, Loss: 0.2661
Epoch 24, Batch 10, Loss: 0.2615
Epoch 24, Batch 20, Loss: 0.2607
Epoch 24, Batch 30, Loss: 0.2599
Epoch 24/30, Loss: 0.2629, Time: 116.80s
Epoch 25, Batch 0, Loss: 0.2644
Epoch 25, Batch 10, Loss: 0.2579
Epoch 25, Batch 20, Loss: 0.2584
Epoch 25, Batch 30, Loss: 0.2636
Epoch 25/30, Loss: 0.2606, Time: 149.65s
Epoch 26, Batch 0, Loss: 0.2591
Epoch 26, Batch 10, Loss: 0.2590
Epoch 26, Batch 20, Loss: 0.2600
Epoch 26, Batch 30, Loss: 0.2612
NOTICE: Validation loss increased in this epoch (1/4).
Epoch 26/30, Loss: 0.2624, Time: 117.32s
Epoch 27, Batch 0, Loss: 0.2601
Epoch 27, Batch 10, Loss: 0.2596
Epoch 27, Batch 20, Loss: 0.2596
Epoch 27, Batch 30, Loss: 0.2662
NOTICE: Validation loss increased in this epoch (2/4).
Epoch 27/30, Loss: 0.2624, Time: 113.01s
Epoch 28, Batch 0, Loss: 0.2591
Epoch 28, Batch 10, Loss: 0.2610
Epoch 28, Batch 20, Loss: 0.2594
Epoch 28, Batch 30, Loss: 0.2584
NOTICE: Validation loss increased in this epoch (3/4).
Epoch 28/30, Loss: 0.2607, Time: 111.01s
Epoch 29, Batch 0, Loss: 0.2722
Epoch 29, Batch 10, Loss: 0.2584
Epoch 29, Batch 20, Loss: 0.2585
Epoch 29, Batch 30, Loss: 0.2571
NOTICE: Validation loss increased in this epoch (4/4).
Epoch 29/30, Loss: 0.2613, Time: 115.61s
NOTICE: Reverting to previous best model state (loss: 0.2606). Ending training
Total time spent in training: 3943.32s
/* Validation */
Validation Loss: 0.2840, Accuracy: 99.05%
/* Saving */
Model saved to output/EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA\model-EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA.pth
Confusion matrix saved to output/EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA\cm-EffNetB0_30ep-BS64_LR1e-3-LS5e-2-BA.png
