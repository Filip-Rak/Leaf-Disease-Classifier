/* Querying */
Enter output directory name: EffNetB0_150ep-BS64_LR1e-3-LS5e-2-BA-AMP
/* Initializing */
Using device: cuda:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU)
/* Training */
Epoch 1, Batch 0, Loss: 1.9469
Epoch 1, Batch 40, Loss: 1.0247
Epoch 1, Batch 80, Loss: 0.9310
Epoch 1, Batch 120, Loss: 0.5111
Epoch 1/150, Loss: 0.8644, Time: 16.13s
Epoch 2, Batch 0, Loss: 0.5635
Epoch 2, Batch 40, Loss: 0.5635
Epoch 2, Batch 80, Loss: 0.4230
Epoch 2, Batch 120, Loss: 0.3194
Epoch 2/150, Loss: 0.4727, Time: 12.13s
Epoch 3, Batch 0, Loss: 0.6182
Epoch 3, Batch 40, Loss: 0.3094
Epoch 3, Batch 80, Loss: 0.8537
Epoch 3, Batch 120, Loss: 0.3686
Epoch 3/150, Loss: 0.3896, Time: 12.07s
Epoch 4, Batch 0, Loss: 0.2860
Epoch 4, Batch 40, Loss: 0.3273
Epoch 4, Batch 80, Loss: 0.2823
Epoch 4, Batch 120, Loss: 0.2986
Epoch 4/150, Loss: 0.3661, Time: 11.92s
Epoch 5, Batch 0, Loss: 0.2941
Epoch 5, Batch 40, Loss: 0.3869
Epoch 5, Batch 80, Loss: 0.3027
Epoch 5, Batch 120, Loss: 0.2972
Epoch 5/150, Loss: 0.3377, Time: 12.30s
Epoch 6, Batch 0, Loss: 0.2828
Epoch 6, Batch 40, Loss: 0.2850
Epoch 6, Batch 80, Loss: 0.2824
Epoch 6, Batch 120, Loss: 0.2824
Epoch 6/150, Loss: 0.3227, Time: 12.22s
Epoch 7, Batch 0, Loss: 0.2890
Epoch 7, Batch 40, Loss: 0.2768
Epoch 7, Batch 80, Loss: 0.2727
Epoch 7, Batch 120, Loss: 0.3541
Epoch 7/150, Loss: 0.3186, Time: 12.20s
Epoch 8, Batch 0, Loss: 0.2995
Epoch 8, Batch 40, Loss: 0.2742
Epoch 8, Batch 80, Loss: 0.2982
Epoch 8, Batch 120, Loss: 0.2833
Epoch 8/150, Loss: 0.3042, Time: 12.20s
Epoch 9, Batch 0, Loss: 0.2845
Epoch 9, Batch 40, Loss: 0.2712
Epoch 9, Batch 80, Loss: 0.3066
Epoch 9, Batch 120, Loss: 0.3124
Epoch 9/150, Loss: 0.3021, Time: 12.17s
Epoch 10, Batch 0, Loss: 0.2711
Epoch 10, Batch 40, Loss: 0.2667
Epoch 10, Batch 80, Loss: 0.2817
Epoch 10, Batch 120, Loss: 0.2727
Epoch 10/150, Loss: 0.2979, Time: 12.21s
Epoch 11, Batch 0, Loss: 0.3408
Epoch 11, Batch 40, Loss: 0.2938
Epoch 11, Batch 80, Loss: 0.2765
Epoch 11, Batch 120, Loss: 0.2738
Epoch 11/150, Loss: 0.2907, Time: 12.35s
Epoch 12, Batch 0, Loss: 0.2768
Epoch 12, Batch 40, Loss: 0.2696
Epoch 12, Batch 80, Loss: 0.2724
Epoch 12, Batch 120, Loss: 0.3354
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 12/150, Loss: 0.3017, Time: 12.47s
Epoch 13, Batch 0, Loss: 0.2759
Epoch 13, Batch 40, Loss: 0.3056
Epoch 13, Batch 80, Loss: 0.2796
Epoch 13, Batch 120, Loss: 0.2690
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 13/150, Loss: 0.2908, Time: 12.16s
Epoch 14, Batch 0, Loss: 0.2796
Epoch 14, Batch 40, Loss: 0.2669
Epoch 14, Batch 80, Loss: 0.2701
Epoch 14, Batch 120, Loss: 0.2667
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 14/150, Loss: 0.2920, Time: 12.17s
Epoch 15, Batch 0, Loss: 0.2679
Epoch 15, Batch 40, Loss: 0.2665
Epoch 15, Batch 80, Loss: 0.2938
Epoch 15, Batch 120, Loss: 0.2923
Epoch 15/150, Loss: 0.2805, Time: 12.43s
Epoch 16, Batch 0, Loss: 0.2637
Epoch 16, Batch 40, Loss: 0.3021
Epoch 16, Batch 80, Loss: 0.2646
Epoch 16, Batch 120, Loss: 0.2620
Epoch 16/150, Loss: 0.2769, Time: 12.50s
Epoch 17, Batch 0, Loss: 0.2646
Epoch 17, Batch 40, Loss: 0.2643
Epoch 17, Batch 80, Loss: 0.2768
Epoch 17, Batch 120, Loss: 0.2629
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 17/150, Loss: 0.2783, Time: 12.49s
Epoch 18, Batch 0, Loss: 0.3102
Epoch 18, Batch 40, Loss: 0.2669
Epoch 18, Batch 80, Loss: 0.2668
Epoch 18, Batch 120, Loss: 0.2614
Epoch 18/150, Loss: 0.2753, Time: 12.63s
Epoch 19, Batch 0, Loss: 0.2768
Epoch 19, Batch 40, Loss: 0.2712
Epoch 19, Batch 80, Loss: 0.2623
Epoch 19, Batch 120, Loss: 0.2708
Epoch 19/150, Loss: 0.2751, Time: 12.26s
Epoch 20, Batch 0, Loss: 0.2680
Epoch 20, Batch 40, Loss: 0.2843
Epoch 20, Batch 80, Loss: 0.2785
Epoch 20, Batch 120, Loss: 0.2694
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 20/150, Loss: 0.2751, Time: 12.30s
Epoch 21, Batch 0, Loss: 0.2673
Epoch 21, Batch 40, Loss: 0.2712
Epoch 21, Batch 80, Loss: 0.2622
Epoch 21, Batch 120, Loss: 0.2835
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 21/150, Loss: 0.2752, Time: 12.26s
Epoch 22, Batch 0, Loss: 0.2614
Epoch 22, Batch 40, Loss: 0.2958
Epoch 22, Batch 80, Loss: 0.2730
Epoch 22, Batch 120, Loss: 0.2651
Epoch 22/150, Loss: 0.2728, Time: 12.38s
Epoch 23, Batch 0, Loss: 0.2642
Epoch 23, Batch 40, Loss: 0.2605
Epoch 23, Batch 80, Loss: 0.2698
Epoch 23, Batch 120, Loss: 0.2654
Epoch 23/150, Loss: 0.2725, Time: 12.50s
Epoch 24, Batch 0, Loss: 0.2659
Epoch 24, Batch 40, Loss: 0.2663
Epoch 24, Batch 80, Loss: 0.2618
Epoch 24, Batch 120, Loss: 0.2615
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 24/150, Loss: 0.2838, Time: 12.27s
Epoch 25, Batch 0, Loss: 0.2574
Epoch 25, Batch 40, Loss: 0.2673
Epoch 25, Batch 80, Loss: 0.2624
Epoch 25, Batch 120, Loss: 0.2619
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 25/150, Loss: 0.2773, Time: 12.37s
Epoch 26, Batch 0, Loss: 0.2655
Epoch 26, Batch 40, Loss: 0.2683
Epoch 26, Batch 80, Loss: 0.2637
Epoch 26, Batch 120, Loss: 0.2635
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 26/150, Loss: 0.2836, Time: 12.14s
Epoch 27, Batch 0, Loss: 0.2599
Epoch 27, Batch 40, Loss: 0.2621
Epoch 27, Batch 80, Loss: 0.2615
Epoch 27, Batch 120, Loss: 0.2625
Epoch 27/150, Loss: 0.2686, Time: 12.18s
Epoch 28, Batch 0, Loss: 0.2596
Epoch 28, Batch 40, Loss: 0.2615
Epoch 28, Batch 80, Loss: 0.3020
Epoch 28, Batch 120, Loss: 0.2587
Epoch 28/150, Loss: 0.2655, Time: 12.19s
Epoch 29, Batch 0, Loss: 0.2601
Epoch 29, Batch 40, Loss: 0.2638
Epoch 29, Batch 80, Loss: 0.2625
Epoch 29, Batch 120, Loss: 0.2982
Epoch 29/150, Loss: 0.2650, Time: 12.08s
Epoch 30, Batch 0, Loss: 0.2593
Epoch 30, Batch 40, Loss: 0.2659
Epoch 30, Batch 80, Loss: 0.2652
Epoch 30, Batch 120, Loss: 0.2667
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 30/150, Loss: 0.2677, Time: 12.13s
Epoch 31, Batch 0, Loss: 0.2683
Epoch 31, Batch 40, Loss: 0.2636
Epoch 31, Batch 80, Loss: 0.2636
Epoch 31, Batch 120, Loss: 0.2587
Epoch 31/150, Loss: 0.2645, Time: 12.02s
Epoch 32, Batch 0, Loss: 0.2625
Epoch 32, Batch 40, Loss: 0.2595
Epoch 32, Batch 80, Loss: 0.2616
Epoch 32, Batch 120, Loss: 0.2591
Epoch 32/150, Loss: 0.2638, Time: 11.99s
Epoch 33, Batch 0, Loss: 0.2609
Epoch 33, Batch 40, Loss: 0.2673
Epoch 33, Batch 80, Loss: 0.2611
Epoch 33, Batch 120, Loss: 0.2599
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 33/150, Loss: 0.2661, Time: 12.01s
Epoch 34, Batch 0, Loss: 0.2619
Epoch 34, Batch 40, Loss: 0.2610
Epoch 34, Batch 80, Loss: 0.2620
Epoch 34, Batch 120, Loss: 0.2677
Epoch 34/150, Loss: 0.2633, Time: 12.22s
Epoch 35, Batch 0, Loss: 0.2696
Epoch 35, Batch 40, Loss: 0.2663
Epoch 35, Batch 80, Loss: 0.2667
Epoch 35, Batch 120, Loss: 0.2588
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 35/150, Loss: 0.2642, Time: 12.21s
Epoch 36, Batch 0, Loss: 0.2617
Epoch 36, Batch 40, Loss: 0.2601
Epoch 36, Batch 80, Loss: 0.2972
Epoch 36, Batch 120, Loss: 0.2588
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 36/150, Loss: 0.2639, Time: 12.14s
Epoch 37, Batch 0, Loss: 0.2568
Epoch 37, Batch 40, Loss: 0.2577
Epoch 37, Batch 80, Loss: 0.2579
Epoch 37, Batch 120, Loss: 0.2625
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 37/150, Loss: 0.2635, Time: 12.09s
Epoch 38, Batch 0, Loss: 0.2592
Epoch 38, Batch 40, Loss: 0.2604
Epoch 38, Batch 80, Loss: 0.2764
Epoch 38, Batch 120, Loss: 0.2574
Epoch 38/150, Loss: 0.2632, Time: 12.12s
Epoch 39, Batch 0, Loss: 0.2572
Epoch 39, Batch 40, Loss: 0.2595
Epoch 39, Batch 80, Loss: 0.2621
Epoch 39, Batch 120, Loss: 0.2682
Epoch 39/150, Loss: 0.2617, Time: 12.11s
Epoch 40, Batch 0, Loss: 0.2592
Epoch 40, Batch 40, Loss: 0.2602
Epoch 40, Batch 80, Loss: 0.2599
Epoch 40, Batch 120, Loss: 0.2601
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 40/150, Loss: 0.2625, Time: 12.08s
Epoch 41, Batch 0, Loss: 0.2606
Epoch 41, Batch 40, Loss: 0.2601
Epoch 41, Batch 80, Loss: 0.2584
Epoch 41, Batch 120, Loss: 0.2596
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 41/150, Loss: 0.2623, Time: 12.18s
Epoch 42, Batch 0, Loss: 0.2601
Epoch 42, Batch 40, Loss: 0.2629
Epoch 42, Batch 80, Loss: 0.2581
Epoch 42, Batch 120, Loss: 0.2576
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 42/150, Loss: 0.2625, Time: 12.02s
Epoch 43, Batch 0, Loss: 0.2573
Epoch 43, Batch 40, Loss: 0.2590
Epoch 43, Batch 80, Loss: 0.2594
Epoch 43, Batch 120, Loss: 0.2580
Epoch 43/150, Loss: 0.2616, Time: 12.15s
Epoch 44, Batch 0, Loss: 0.2599
Epoch 44, Batch 40, Loss: 0.2584
Epoch 44, Batch 80, Loss: 0.2594
Epoch 44, Batch 120, Loss: 0.2628
Epoch 44/150, Loss: 0.2602, Time: 12.01s
Epoch 45, Batch 0, Loss: 0.2594
Epoch 45, Batch 40, Loss: 0.2594
Epoch 45, Batch 80, Loss: 0.2591
Epoch 45, Batch 120, Loss: 0.2582
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 45/150, Loss: 0.2647, Time: 12.02s
Epoch 46, Batch 0, Loss: 0.2599
Epoch 46, Batch 40, Loss: 0.2590
Epoch 46, Batch 80, Loss: 0.2596
Epoch 46, Batch 120, Loss: 0.2602
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 46/150, Loss: 0.2627, Time: 12.19s
Epoch 47, Batch 0, Loss: 0.2601
Epoch 47, Batch 40, Loss: 0.2602
Epoch 47, Batch 80, Loss: 0.2601
Epoch 47, Batch 120, Loss: 0.2615
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 47/150, Loss: 0.2689, Time: 12.22s
Epoch 48, Batch 0, Loss: 0.2596
Epoch 48, Batch 40, Loss: 0.2603
Epoch 48, Batch 80, Loss: 0.2580
Epoch 48, Batch 120, Loss: 0.2580
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 48/150, Loss: 0.2615, Time: 12.14s
Epoch 49, Batch 0, Loss: 0.2601
Epoch 49, Batch 40, Loss: 0.2572
Epoch 49, Batch 80, Loss: 0.2562
Epoch 49, Batch 120, Loss: 0.2577
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 49/150, Loss: 0.2608, Time: 11.98s
Epoch 50, Batch 0, Loss: 0.2597
Epoch 50, Batch 40, Loss: 0.2587
Epoch 50, Batch 80, Loss: 0.2585
Epoch 50, Batch 120, Loss: 0.2579
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 50/150, Loss: 0.2649, Time: 12.06s
Epoch 51, Batch 0, Loss: 0.2585
Epoch 51, Batch 40, Loss: 0.2580
Epoch 51, Batch 80, Loss: 0.2560
Epoch 51, Batch 120, Loss: 0.2576
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 51/150, Loss: 0.2610, Time: 12.19s
Epoch 52, Batch 0, Loss: 0.2564
Epoch 52, Batch 40, Loss: 0.2680
Epoch 52, Batch 80, Loss: 0.2574
Epoch 52, Batch 120, Loss: 0.2567
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 52/150, Loss: 0.2676, Time: 12.20s
Epoch 53, Batch 0, Loss: 0.2611
Epoch 53, Batch 40, Loss: 0.2588
Epoch 53, Batch 80, Loss: 0.2579
Epoch 53, Batch 120, Loss: 0.2569
NOTICE: Validation loss increased in this epoch (9/151).
Epoch 53/150, Loss: 0.2607, Time: 12.14s
Epoch 54, Batch 0, Loss: 0.2606
Epoch 54, Batch 40, Loss: 0.2584
Epoch 54, Batch 80, Loss: 0.2599
Epoch 54, Batch 120, Loss: 0.2577
NOTICE: Validation loss increased in this epoch (10/151).
Epoch 54/150, Loss: 0.2610, Time: 12.03s
Epoch 55, Batch 0, Loss: 0.2604
Epoch 55, Batch 40, Loss: 0.2609
Epoch 55, Batch 80, Loss: 0.2613
Epoch 55, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (11/151).
Epoch 55/150, Loss: 0.2613, Time: 12.00s
Epoch 56, Batch 0, Loss: 0.2623
Epoch 56, Batch 40, Loss: 0.2585
Epoch 56, Batch 80, Loss: 0.2570
Epoch 56, Batch 120, Loss: 0.2605
NOTICE: Validation loss increased in this epoch (12/151).
Epoch 56/150, Loss: 0.2615, Time: 12.12s
Epoch 57, Batch 0, Loss: 0.2585
Epoch 57, Batch 40, Loss: 0.2595
Epoch 57, Batch 80, Loss: 0.2566
Epoch 57, Batch 120, Loss: 0.2592
Epoch 57/150, Loss: 0.2597, Time: 12.12s
Epoch 58, Batch 0, Loss: 0.2720
Epoch 58, Batch 40, Loss: 0.2617
Epoch 58, Batch 80, Loss: 0.2595
Epoch 58, Batch 120, Loss: 0.2587
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 58/150, Loss: 0.2719, Time: 12.15s
Epoch 59, Batch 0, Loss: 0.2615
Epoch 59, Batch 40, Loss: 0.2618
Epoch 59, Batch 80, Loss: 0.2588
Epoch 59, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 59/150, Loss: 0.2615, Time: 12.00s
Epoch 60, Batch 0, Loss: 0.2575
Epoch 60, Batch 40, Loss: 0.2612
Epoch 60, Batch 80, Loss: 0.2588
Epoch 60, Batch 120, Loss: 0.2582
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 60/150, Loss: 0.2610, Time: 12.13s
Epoch 61, Batch 0, Loss: 0.2573
Epoch 61, Batch 40, Loss: 0.2603
Epoch 61, Batch 80, Loss: 0.2582
Epoch 61, Batch 120, Loss: 0.2573
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 61/150, Loss: 0.2611, Time: 12.03s
Epoch 62, Batch 0, Loss: 0.2570
Epoch 62, Batch 40, Loss: 0.2581
Epoch 62, Batch 80, Loss: 0.2585
Epoch 62, Batch 120, Loss: 0.2588
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 62/150, Loss: 0.2657, Time: 11.99s
Epoch 63, Batch 0, Loss: 0.2819
Epoch 63, Batch 40, Loss: 0.2586
Epoch 63, Batch 80, Loss: 0.2578
Epoch 63, Batch 120, Loss: 0.2570
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 63/150, Loss: 0.2710, Time: 11.99s
Epoch 64, Batch 0, Loss: 0.2572
Epoch 64, Batch 40, Loss: 0.2585
Epoch 64, Batch 80, Loss: 0.2599
Epoch 64, Batch 120, Loss: 0.2576
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 64/150, Loss: 0.2640, Time: 11.99s
Epoch 65, Batch 0, Loss: 0.2582
Epoch 65, Batch 40, Loss: 0.2608
Epoch 65, Batch 80, Loss: 0.2579
Epoch 65, Batch 120, Loss: 0.2566
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 65/150, Loss: 0.2702, Time: 12.05s
Epoch 66, Batch 0, Loss: 0.2587
Epoch 66, Batch 40, Loss: 0.2582
Epoch 66, Batch 80, Loss: 0.2587
Epoch 66, Batch 120, Loss: 0.2595
NOTICE: Validation loss increased in this epoch (9/151).
Epoch 66/150, Loss: 0.2612, Time: 12.08s
Epoch 67, Batch 0, Loss: 0.2623
Epoch 67, Batch 40, Loss: 0.2582
Epoch 67, Batch 80, Loss: 0.2578
Epoch 67, Batch 120, Loss: 0.2571
NOTICE: Validation loss increased in this epoch (10/151).
Epoch 67/150, Loss: 0.2621, Time: 12.10s
Epoch 68, Batch 0, Loss: 0.2587
Epoch 68, Batch 40, Loss: 0.2597
Epoch 68, Batch 80, Loss: 0.2574
Epoch 68, Batch 120, Loss: 0.2577
NOTICE: Validation loss increased in this epoch (11/151).
Epoch 68/150, Loss: 0.2617, Time: 12.02s
Epoch 69, Batch 0, Loss: 0.2596
Epoch 69, Batch 40, Loss: 0.2581
Epoch 69, Batch 80, Loss: 0.2579
Epoch 69, Batch 120, Loss: 0.2567
NOTICE: Validation loss increased in this epoch (12/151).
Epoch 69/150, Loss: 0.2602, Time: 11.97s
Epoch 70, Batch 0, Loss: 0.2566
Epoch 70, Batch 40, Loss: 0.2574
Epoch 70, Batch 80, Loss: 0.2646
Epoch 70, Batch 120, Loss: 0.2597
NOTICE: Validation loss increased in this epoch (13/151).
Epoch 70/150, Loss: 0.2609, Time: 11.98s
Epoch 71, Batch 0, Loss: 0.2619
Epoch 71, Batch 40, Loss: 0.2595
Epoch 71, Batch 80, Loss: 0.2590
Epoch 71, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (14/151).
Epoch 71/150, Loss: 0.2613, Time: 12.22s
Epoch 72, Batch 0, Loss: 0.2575
Epoch 72, Batch 40, Loss: 0.2581
Epoch 72, Batch 80, Loss: 0.2571
Epoch 72, Batch 120, Loss: 0.2591
NOTICE: Validation loss increased in this epoch (15/151).
Epoch 72/150, Loss: 0.2663, Time: 11.96s
Epoch 73, Batch 0, Loss: 0.2696
Epoch 73, Batch 40, Loss: 0.2590
Epoch 73, Batch 80, Loss: 0.2573
Epoch 73, Batch 120, Loss: 0.2588
NOTICE: Validation loss increased in this epoch (16/151).
Epoch 73/150, Loss: 0.2675, Time: 12.06s
Epoch 74, Batch 0, Loss: 0.2965
Epoch 74, Batch 40, Loss: 0.2591
Epoch 74, Batch 80, Loss: 0.2622
Epoch 74, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (17/151).
Epoch 74/150, Loss: 0.2686, Time: 12.11s
Epoch 75, Batch 0, Loss: 0.2598
Epoch 75, Batch 40, Loss: 0.2567
Epoch 75, Batch 80, Loss: 0.2567
Epoch 75, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (18/151).
Epoch 75/150, Loss: 0.2669, Time: 12.25s
Epoch 76, Batch 0, Loss: 0.2580
Epoch 76, Batch 40, Loss: 0.2591
Epoch 76, Batch 80, Loss: 0.2580
Epoch 76, Batch 120, Loss: 0.2591
NOTICE: Validation loss increased in this epoch (19/151).
Epoch 76/150, Loss: 0.2723, Time: 12.17s
Epoch 77, Batch 0, Loss: 0.2581
Epoch 77, Batch 40, Loss: 0.2611
Epoch 77, Batch 80, Loss: 0.2602
Epoch 77, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (20/151).
Epoch 77/150, Loss: 0.2603, Time: 12.05s
Epoch 78, Batch 0, Loss: 0.2588
Epoch 78, Batch 40, Loss: 0.2577
Epoch 78, Batch 80, Loss: 0.2604
Epoch 78, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (21/151).
Epoch 78/150, Loss: 0.2610, Time: 11.95s
Epoch 79, Batch 0, Loss: 0.2598
Epoch 79, Batch 40, Loss: 0.2566
Epoch 79, Batch 80, Loss: 0.2569
Epoch 79, Batch 120, Loss: 0.2580
NOTICE: Validation loss increased in this epoch (22/151).
Epoch 79/150, Loss: 0.2642, Time: 12.02s
Epoch 80, Batch 0, Loss: 0.2568
Epoch 80, Batch 40, Loss: 0.2602
Epoch 80, Batch 80, Loss: 0.2581
Epoch 80, Batch 120, Loss: 0.2587
Epoch 80/150, Loss: 0.2595, Time: 11.99s
Epoch 81, Batch 0, Loss: 0.2842
Epoch 81, Batch 40, Loss: 0.2579
Epoch 81, Batch 80, Loss: 0.2586
Epoch 81, Batch 120, Loss: 0.2572
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 81/150, Loss: 0.2602, Time: 11.98s
Epoch 82, Batch 0, Loss: 0.2584
Epoch 82, Batch 40, Loss: 0.2613
Epoch 82, Batch 80, Loss: 0.2613
Epoch 82, Batch 120, Loss: 0.2598
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 82/150, Loss: 0.2615, Time: 11.99s
Epoch 83, Batch 0, Loss: 0.2595
Epoch 83, Batch 40, Loss: 0.2565
Epoch 83, Batch 80, Loss: 0.2581
Epoch 83, Batch 120, Loss: 0.2613
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 83/150, Loss: 0.2608, Time: 12.00s
Epoch 84, Batch 0, Loss: 0.2569
Epoch 84, Batch 40, Loss: 0.2578
Epoch 84, Batch 80, Loss: 0.2569
Epoch 84, Batch 120, Loss: 0.2601
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 84/150, Loss: 0.2597, Time: 11.96s
Epoch 85, Batch 0, Loss: 0.2575
Epoch 85, Batch 40, Loss: 0.2596
Epoch 85, Batch 80, Loss: 0.2562
Epoch 85, Batch 120, Loss: 0.2586
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 85/150, Loss: 0.2621, Time: 12.02s
Epoch 86, Batch 0, Loss: 0.2628
Epoch 86, Batch 40, Loss: 0.2582
Epoch 86, Batch 80, Loss: 0.2585
Epoch 86, Batch 120, Loss: 0.2599
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 86/150, Loss: 0.2610, Time: 11.97s
Epoch 87, Batch 0, Loss: 0.2584
Epoch 87, Batch 40, Loss: 0.2566
Epoch 87, Batch 80, Loss: 0.2567
Epoch 87, Batch 120, Loss: 0.2574
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 87/150, Loss: 0.2598, Time: 12.00s
Epoch 88, Batch 0, Loss: 0.2596
Epoch 88, Batch 40, Loss: 0.2593
Epoch 88, Batch 80, Loss: 0.2565
Epoch 88, Batch 120, Loss: 0.2576
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 88/150, Loss: 0.2679, Time: 12.02s
Epoch 89, Batch 0, Loss: 0.2587
Epoch 89, Batch 40, Loss: 0.2591
Epoch 89, Batch 80, Loss: 0.2601
Epoch 89, Batch 120, Loss: 0.2570
Epoch 89/150, Loss: 0.2594, Time: 11.99s
Epoch 90, Batch 0, Loss: 0.2591
Epoch 90, Batch 40, Loss: 0.2594
Epoch 90, Batch 80, Loss: 0.2609
Epoch 90, Batch 120, Loss: 0.2564
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 90/150, Loss: 0.2633, Time: 11.98s
Epoch 91, Batch 0, Loss: 0.2644
Epoch 91, Batch 40, Loss: 0.2578
Epoch 91, Batch 80, Loss: 0.2571
Epoch 91, Batch 120, Loss: 0.2579
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 91/150, Loss: 0.2612, Time: 12.00s
Epoch 92, Batch 0, Loss: 0.2576
Epoch 92, Batch 40, Loss: 0.2562
Epoch 92, Batch 80, Loss: 0.2571
Epoch 92, Batch 120, Loss: 0.2558
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 92/150, Loss: 0.2595, Time: 11.99s
Epoch 93, Batch 0, Loss: 0.2585
Epoch 93, Batch 40, Loss: 0.2630
Epoch 93, Batch 80, Loss: 0.2586
Epoch 93, Batch 120, Loss: 0.2570
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 93/150, Loss: 0.2601, Time: 12.02s
Epoch 94, Batch 0, Loss: 0.2591
Epoch 94, Batch 40, Loss: 0.2613
Epoch 94, Batch 80, Loss: 0.2611
Epoch 94, Batch 120, Loss: 0.2592
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 94/150, Loss: 0.2657, Time: 11.96s
Epoch 95, Batch 0, Loss: 0.2578
Epoch 95, Batch 40, Loss: 0.2571
Epoch 95, Batch 80, Loss: 0.2585
Epoch 95, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 95/150, Loss: 0.2662, Time: 12.02s
Epoch 96, Batch 0, Loss: 0.2566
Epoch 96, Batch 40, Loss: 0.2582
Epoch 96, Batch 80, Loss: 0.2574
Epoch 96, Batch 120, Loss: 0.2577
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 96/150, Loss: 0.2749, Time: 12.00s
Epoch 97, Batch 0, Loss: 0.2591
Epoch 97, Batch 40, Loss: 0.2564
Epoch 97, Batch 80, Loss: 0.2751
Epoch 97, Batch 120, Loss: 0.2591
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 97/150, Loss: 0.2624, Time: 11.98s
Epoch 98, Batch 0, Loss: 0.2596
Epoch 98, Batch 40, Loss: 0.2615
Epoch 98, Batch 80, Loss: 0.2579
Epoch 98, Batch 120, Loss: 0.2657
NOTICE: Validation loss increased in this epoch (9/151).
Epoch 98/150, Loss: 0.2602, Time: 11.99s
Epoch 99, Batch 0, Loss: 0.2606
Epoch 99, Batch 40, Loss: 0.2590
Epoch 99, Batch 80, Loss: 0.2612
Epoch 99, Batch 120, Loss: 0.2565
NOTICE: Validation loss increased in this epoch (10/151).
Epoch 99/150, Loss: 0.2613, Time: 12.04s
Epoch 100, Batch 0, Loss: 0.2571
Epoch 100, Batch 40, Loss: 0.2596
Epoch 100, Batch 80, Loss: 0.2584
Epoch 100, Batch 120, Loss: 0.2570
Epoch 100/150, Loss: 0.2594, Time: 12.01s
Epoch 101, Batch 0, Loss: 0.2579
Epoch 101, Batch 40, Loss: 0.2595
Epoch 101, Batch 80, Loss: 0.2583
Epoch 101, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 101/150, Loss: 0.2716, Time: 12.00s
Epoch 102, Batch 0, Loss: 0.2605
Epoch 102, Batch 40, Loss: 0.2603
Epoch 102, Batch 80, Loss: 0.2585
Epoch 102, Batch 120, Loss: 0.2561
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 102/150, Loss: 0.2686, Time: 11.97s
Epoch 103, Batch 0, Loss: 0.2608
Epoch 103, Batch 40, Loss: 0.2612
Epoch 103, Batch 80, Loss: 0.2573
Epoch 103, Batch 120, Loss: 0.2573
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 103/150, Loss: 0.2719, Time: 11.98s
Epoch 104, Batch 0, Loss: 0.2596
Epoch 104, Batch 40, Loss: 0.2607
Epoch 104, Batch 80, Loss: 0.2567
Epoch 104, Batch 120, Loss: 0.2651
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 104/150, Loss: 0.2611, Time: 12.02s
Epoch 105, Batch 0, Loss: 0.2599
Epoch 105, Batch 40, Loss: 0.2571
Epoch 105, Batch 80, Loss: 0.2576
Epoch 105, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 105/150, Loss: 0.2612, Time: 12.00s
Epoch 106, Batch 0, Loss: 0.2594
Epoch 106, Batch 40, Loss: 0.2656
Epoch 106, Batch 80, Loss: 0.2602
Epoch 106, Batch 120, Loss: 0.2590
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 106/150, Loss: 0.2667, Time: 11.97s
Epoch 107, Batch 0, Loss: 0.2567
Epoch 107, Batch 40, Loss: 0.2579
Epoch 107, Batch 80, Loss: 0.2571
Epoch 107, Batch 120, Loss: 0.2573
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 107/150, Loss: 0.2614, Time: 12.03s
Epoch 108, Batch 0, Loss: 0.2624
Epoch 108, Batch 40, Loss: 0.2568
Epoch 108, Batch 80, Loss: 0.2577
Epoch 108, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 108/150, Loss: 0.2635, Time: 11.97s
Epoch 109, Batch 0, Loss: 0.2573
Epoch 109, Batch 40, Loss: 0.2612
Epoch 109, Batch 80, Loss: 0.2610
Epoch 109, Batch 120, Loss: 0.2566
NOTICE: Validation loss increased in this epoch (9/151).
Epoch 109/150, Loss: 0.2606, Time: 12.02s
Epoch 110, Batch 0, Loss: 0.2608
Epoch 110, Batch 40, Loss: 0.2572
Epoch 110, Batch 80, Loss: 0.2597
Epoch 110, Batch 120, Loss: 0.2575
NOTICE: Validation loss increased in this epoch (10/151).
Epoch 110/150, Loss: 0.2606, Time: 11.98s
Epoch 111, Batch 0, Loss: 0.2606
Epoch 111, Batch 40, Loss: 0.2585
Epoch 111, Batch 80, Loss: 0.2566
Epoch 111, Batch 120, Loss: 0.2583
NOTICE: Validation loss increased in this epoch (11/151).
Epoch 111/150, Loss: 0.2604, Time: 12.16s
Epoch 112, Batch 0, Loss: 0.2585
Epoch 112, Batch 40, Loss: 0.2639
Epoch 112, Batch 80, Loss: 0.2590
Epoch 112, Batch 120, Loss: 0.2580
NOTICE: Validation loss increased in this epoch (12/151).
Epoch 112/150, Loss: 0.2602, Time: 12.02s
Epoch 113, Batch 0, Loss: 0.2571
Epoch 113, Batch 40, Loss: 0.2587
Epoch 113, Batch 80, Loss: 0.2571
Epoch 113, Batch 120, Loss: 0.2570
NOTICE: Validation loss increased in this epoch (13/151).
Epoch 113/150, Loss: 0.2599, Time: 12.01s
Epoch 114, Batch 0, Loss: 0.2608
Epoch 114, Batch 40, Loss: 0.2554
Epoch 114, Batch 80, Loss: 0.2612
Epoch 114, Batch 120, Loss: 0.2585
NOTICE: Validation loss increased in this epoch (14/151).
Epoch 114/150, Loss: 0.2606, Time: 11.96s
Epoch 115, Batch 0, Loss: 0.2584
Epoch 115, Batch 40, Loss: 0.2596
Epoch 115, Batch 80, Loss: 0.2600
Epoch 115, Batch 120, Loss: 0.2591
NOTICE: Validation loss increased in this epoch (15/151).
Epoch 115/150, Loss: 0.2602, Time: 11.99s
Epoch 116, Batch 0, Loss: 0.2598
Epoch 116, Batch 40, Loss: 0.2570
Epoch 116, Batch 80, Loss: 0.2570
Epoch 116, Batch 120, Loss: 0.2568
NOTICE: Validation loss increased in this epoch (16/151).
Epoch 116/150, Loss: 0.2604, Time: 12.02s
Epoch 117, Batch 0, Loss: 0.2562
Epoch 117, Batch 40, Loss: 0.2567
Epoch 117, Batch 80, Loss: 0.2578
Epoch 117, Batch 120, Loss: 0.2583
Epoch 117/150, Loss: 0.2592, Time: 12.02s
Epoch 118, Batch 0, Loss: 0.2592
Epoch 118, Batch 40, Loss: 0.2608
Epoch 118, Batch 80, Loss: 0.2567
Epoch 118, Batch 120, Loss: 0.2856
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 118/150, Loss: 0.2603, Time: 11.99s
Epoch 119, Batch 0, Loss: 0.2618
Epoch 119, Batch 40, Loss: 0.2597
Epoch 119, Batch 80, Loss: 0.2579
Epoch 119, Batch 120, Loss: 0.2600
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 119/150, Loss: 0.2611, Time: 12.11s
Epoch 120, Batch 0, Loss: 0.2596
Epoch 120, Batch 40, Loss: 0.2595
Epoch 120, Batch 80, Loss: 0.2580
Epoch 120, Batch 120, Loss: 0.2561
Epoch 120/150, Loss: 0.2592, Time: 12.09s
Epoch 121, Batch 0, Loss: 0.2580
Epoch 121, Batch 40, Loss: 0.2619
Epoch 121, Batch 80, Loss: 0.2660
Epoch 121, Batch 120, Loss: 0.2572
NOTICE: Validation loss increased in this epoch (1/151).
Epoch 121/150, Loss: 0.2629, Time: 11.99s
Epoch 122, Batch 0, Loss: 0.2594
Epoch 122, Batch 40, Loss: 0.2589
Epoch 122, Batch 80, Loss: 0.2606
Epoch 122, Batch 120, Loss: 0.2577
NOTICE: Validation loss increased in this epoch (2/151).
Epoch 122/150, Loss: 0.2605, Time: 12.00s
Epoch 123, Batch 0, Loss: 0.2574
Epoch 123, Batch 40, Loss: 0.2583
Epoch 123, Batch 80, Loss: 0.2573
Epoch 123, Batch 120, Loss: 0.2568
NOTICE: Validation loss increased in this epoch (3/151).
Epoch 123/150, Loss: 0.2616, Time: 12.00s
Epoch 124, Batch 0, Loss: 0.2599
Epoch 124, Batch 40, Loss: 0.2667
Epoch 124, Batch 80, Loss: 0.2580
Epoch 124, Batch 120, Loss: 0.2574
NOTICE: Validation loss increased in this epoch (4/151).
Epoch 124/150, Loss: 0.2603, Time: 12.01s
Epoch 125, Batch 0, Loss: 0.2581
Epoch 125, Batch 40, Loss: 0.2598
Epoch 125, Batch 80, Loss: 0.2606
Epoch 125, Batch 120, Loss: 0.2588
NOTICE: Validation loss increased in this epoch (5/151).
Epoch 125/150, Loss: 0.2603, Time: 12.20s
Epoch 126, Batch 0, Loss: 0.2594
Epoch 126, Batch 40, Loss: 0.2629
Epoch 126, Batch 80, Loss: 0.2595
Epoch 126, Batch 120, Loss: 0.2565
NOTICE: Validation loss increased in this epoch (6/151).
Epoch 126/150, Loss: 0.2623, Time: 11.96s
Epoch 127, Batch 0, Loss: 0.2580
Epoch 127, Batch 40, Loss: 0.2570
Epoch 127, Batch 80, Loss: 0.2565
Epoch 127, Batch 120, Loss: 0.2570
NOTICE: Validation loss increased in this epoch (7/151).
Epoch 127/150, Loss: 0.2604, Time: 11.99s
Epoch 128, Batch 0, Loss: 0.2634
Epoch 128, Batch 40, Loss: 0.2570
Epoch 128, Batch 80, Loss: 0.2585
Epoch 128, Batch 120, Loss: 0.2596
NOTICE: Validation loss increased in this epoch (8/151).
Epoch 128/150, Loss: 0.2616, Time: 11.99s
Epoch 129, Batch 0, Loss: 0.2570
Epoch 129, Batch 40, Loss: 0.2572
Epoch 129, Batch 80, Loss: 0.2575
Epoch 129, Batch 120, Loss: 0.2592
NOTICE: Validation loss increased in this epoch (9/151).
Epoch 129/150, Loss: 0.2610, Time: 12.05s
Epoch 130, Batch 0, Loss: 0.2615
Epoch 130, Batch 40, Loss: 0.2594
Epoch 130, Batch 80, Loss: 0.2594
Epoch 130, Batch 120, Loss: 0.2571
NOTICE: Validation loss increased in this epoch (10/151).
Epoch 130/150, Loss: 0.2599, Time: 11.95s
Epoch 131, Batch 0, Loss: 0.2594
Epoch 131, Batch 40, Loss: 0.2586
Epoch 131, Batch 80, Loss: 0.2583
Epoch 131, Batch 120, Loss: 0.2585
NOTICE: Validation loss increased in this epoch (11/151).
Epoch 131/150, Loss: 0.2636, Time: 12.00s
Epoch 132, Batch 0, Loss: 0.2579
Epoch 132, Batch 40, Loss: 0.2572
Epoch 132, Batch 80, Loss: 0.2604
Epoch 132, Batch 120, Loss: 0.2607
NOTICE: Validation loss increased in this epoch (12/151).
Epoch 132/150, Loss: 0.2604, Time: 11.99s
Epoch 133, Batch 0, Loss: 0.2577
Epoch 133, Batch 40, Loss: 0.3294
Epoch 133, Batch 80, Loss: 0.2611
Epoch 133, Batch 120, Loss: 0.2624
NOTICE: Validation loss increased in this epoch (13/151).
Epoch 133/150, Loss: 0.2598, Time: 12.03s
Epoch 134, Batch 0, Loss: 0.2581
Epoch 134, Batch 40, Loss: 0.2570
Epoch 134, Batch 80, Loss: 0.2574
Epoch 134, Batch 120, Loss: 0.2571
NOTICE: Validation loss increased in this epoch (14/151).
Epoch 134/150, Loss: 0.2620, Time: 11.97s
Epoch 135, Batch 0, Loss: 0.2586
Epoch 135, Batch 40, Loss: 0.2572
Epoch 135, Batch 80, Loss: 0.2603
Epoch 135, Batch 120, Loss: 0.2608
NOTICE: Validation loss increased in this epoch (15/151).
Epoch 135/150, Loss: 0.2740, Time: 12.00s
Epoch 136, Batch 0, Loss: 0.2573
Epoch 136, Batch 40, Loss: 0.2581
Epoch 136, Batch 80, Loss: 0.2573
Epoch 136, Batch 120, Loss: 0.2632
NOTICE: Validation loss increased in this epoch (16/151).
Epoch 136/150, Loss: 0.2629, Time: 11.99s
Epoch 137, Batch 0, Loss: 0.2586
Epoch 137, Batch 40, Loss: 0.2569
Epoch 137, Batch 80, Loss: 0.2582
Epoch 137, Batch 120, Loss: 0.2565
NOTICE: Validation loss increased in this epoch (17/151).
Epoch 137/150, Loss: 0.2700, Time: 12.01s
Epoch 138, Batch 0, Loss: 0.2580
Epoch 138, Batch 40, Loss: 0.2589
Epoch 138, Batch 80, Loss: 0.2608
Epoch 138, Batch 120, Loss: 0.2710
NOTICE: Validation loss increased in this epoch (18/151).
Epoch 138/150, Loss: 0.2598, Time: 12.00s
Epoch 139, Batch 0, Loss: 0.2606
Epoch 139, Batch 40, Loss: 0.2588
Epoch 139, Batch 80, Loss: 0.2774
Epoch 139, Batch 120, Loss: 0.2604
NOTICE: Validation loss increased in this epoch (19/151).
Epoch 139/150, Loss: 0.2596, Time: 12.04s
Epoch 140, Batch 0, Loss: 0.2601
Epoch 140, Batch 40, Loss: 0.2612
Epoch 140, Batch 80, Loss: 0.2589
Epoch 140, Batch 120, Loss: 0.2687
NOTICE: Validation loss increased in this epoch (20/151).
Epoch 140/150, Loss: 0.2594, Time: 12.11s
Epoch 141, Batch 0, Loss: 0.2665
Epoch 141, Batch 40, Loss: 0.2595
Epoch 141, Batch 80, Loss: 0.2558
Epoch 141, Batch 120, Loss: 0.2608
NOTICE: Validation loss increased in this epoch (21/151).
Epoch 141/150, Loss: 0.2604, Time: 12.00s
Epoch 142, Batch 0, Loss: 0.2587
Epoch 142, Batch 40, Loss: 0.2596
Epoch 142, Batch 80, Loss: 0.2621
Epoch 142, Batch 120, Loss: 0.2580
NOTICE: Validation loss increased in this epoch (22/151).
Epoch 142/150, Loss: 0.2685, Time: 11.99s
Epoch 143, Batch 0, Loss: 0.2583
Epoch 143, Batch 40, Loss: 0.2597
Epoch 143, Batch 80, Loss: 0.2597
Epoch 143, Batch 120, Loss: 0.2594
NOTICE: Validation loss increased in this epoch (23/151).
Epoch 143/150, Loss: 0.2710, Time: 12.06s
Epoch 144, Batch 0, Loss: 0.2570
Epoch 144, Batch 40, Loss: 0.2567
Epoch 144, Batch 80, Loss: 0.2584
Epoch 144, Batch 120, Loss: 0.2581
NOTICE: Validation loss increased in this epoch (24/151).
Epoch 144/150, Loss: 0.2605, Time: 11.93s
Epoch 145, Batch 0, Loss: 0.2570
Epoch 145, Batch 40, Loss: 0.2701
Epoch 145, Batch 80, Loss: 0.2585
Epoch 145, Batch 120, Loss: 0.2574
NOTICE: Validation loss increased in this epoch (25/151).
Epoch 145/150, Loss: 0.2609, Time: 12.04s
Epoch 146, Batch 0, Loss: 0.2586
Epoch 146, Batch 40, Loss: 0.2612
Epoch 146, Batch 80, Loss: 0.2593
Epoch 146, Batch 120, Loss: 0.2562
NOTICE: Validation loss increased in this epoch (26/151).
Epoch 146/150, Loss: 0.2604, Time: 12.00s
Epoch 147, Batch 0, Loss: 0.2577
Epoch 147, Batch 40, Loss: 0.2576
Epoch 147, Batch 80, Loss: 0.2585
Epoch 147, Batch 120, Loss: 0.2569
NOTICE: Validation loss increased in this epoch (27/151).
Epoch 147/150, Loss: 0.2658, Time: 11.99s
Epoch 148, Batch 0, Loss: 0.2574
Epoch 148, Batch 40, Loss: 0.2604
Epoch 148, Batch 80, Loss: 0.2608
Epoch 148, Batch 120, Loss: 0.2599
NOTICE: Validation loss increased in this epoch (28/151).
Epoch 148/150, Loss: 0.2714, Time: 11.97s
Epoch 149, Batch 0, Loss: 0.2596
Epoch 149, Batch 40, Loss: 0.2580
Epoch 149, Batch 80, Loss: 0.2577
Epoch 149, Batch 120, Loss: 0.2633
NOTICE: Validation loss increased in this epoch (29/151).
Epoch 149/150, Loss: 0.2599, Time: 12.00s
Epoch 150, Batch 0, Loss: 0.2576
Epoch 150, Batch 40, Loss: 0.2602
Epoch 150, Batch 80, Loss: 0.2589
Epoch 150, Batch 120, Loss: 0.2589
NOTICE: Validation loss increased in this epoch (30/151).
Epoch 150/150, Loss: 0.2609, Time: 11.99s
Total time spent in training: 1816.27s
/* Validation */
Validation Loss: 0.2894, Accuracy: 98.86%
/* Saving */
Model saved to output/EffNetB0_150ep-BS64_LR1e-3-LS5e-2-BA-AMP\model-EffNetB0_150ep-BS64_LR1e-3-LS5e-2-BA-AMP.pth
Confusion matrix saved to output/EffNetB0_150ep-BS64_LR1e-3-LS5e-2-BA-AMP\cm-EffNetB0_150ep-BS64_LR1e-3-LS5e-2-BA-AMP.png
